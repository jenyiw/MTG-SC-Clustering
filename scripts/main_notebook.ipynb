{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5aa0b9",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df09c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Own packages\n",
    "import louvainFunctions_v3 as lF\n",
    "import markergeneFunctions as mgF\n",
    "import plotumapFunctions as puF\n",
    "import evaluation as ev\n",
    "import gnbFunctions as gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579fe253",
   "metadata": {},
   "source": [
    "# Pre-process data and dimensionality reduction\n",
    "\n",
    "Log transform and normalization, dimensionality reduction using PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bba29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"../output/data_loaded.csv\", dtype=float, delimiter=\",\")\n",
    "data[data == 0.0] = 0.0000001\n",
    "print(\"Data is loaded. Now taking log-transform. \")\n",
    "\n",
    "data = log_transform(data)\n",
    "print(\"Data is transformed. Now scaling.\")\n",
    "\n",
    "data = scale(data)\n",
    "print(\"Data is mean-centred. Now performing PCA.\")\n",
    "\n",
    "variances, reduced_data = perform_pca(data)\n",
    "print(\"PCA successful! Now saving data.\")\n",
    "\n",
    "sample = reduced_data[:500, :]\n",
    "np.savetxt(\"../output/reduced_sample_20_PCs.csv\", sample, delimiter=\",\", fmt=\"%.2f\")\n",
    "\n",
    "np.savetxt(\"../output/reduced_data_20_PCs.csv\", reduced_data, delimiter=\",\", fmt=\"%.2f\")\n",
    "print(\"Data saved! Now plotting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35407a28",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = None\n",
    "if dirpath is None:\n",
    "    raise Exception(r'MAKE DIRPATH YOUR DIRECTORY SUCH THAT THE FOLDER \"data\" IS IN THE DIRECTORY')\n",
    "os.chdir(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(os.path.join(r'.\\data', 'reduced_sample_20_PCs.csv'), delimiter=',')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca78ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import larger dataset\n",
    "large_data = np.loadtxt(os.path.join(r'.\\data', 'reduced_data_20_PCs.csv'), delimiter=',')\n",
    "print(large_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665cac9",
   "metadata": {},
   "source": [
    "# Test against GMMs from package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be46a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "membership_arr_gmm = GaussianMixture(n_components=23, random_state=0, n_init = 20).fit_predict(large_data)\n",
    "save_dir = os.path.join(os.getcwd(), 'output')\n",
    "save_path = os.path.join(save_dir, 'gmm_clusters.txt')\n",
    "np.savetxt(save_path, membership_arr_gmm[np.newaxis, :], fmt = '%d')\n",
    "np.save('membership_arr_gmm_29.npy', membership_arr_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63387bd5",
   "metadata": {},
   "source": [
    "# Run Louvain\n",
    "Will create an array of labels with dimensions (# of samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "membership_arr_louvain = lF.louvain_clustering(large_data, graph_style='kNN', k=20,)\n",
    "np.save('./output/membership_arr_louvain_large_k20_knn.npy', membership_arr_louvain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f5a912",
   "metadata": {},
   "source": [
    "# Test against Louvain from package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3d9c5",
   "metadata": {},
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from louvainFunctions import create_kNN_graph\n",
    "\n",
    "edge_list, edge_weights = lF.create_kNN_graph(data, 5)\n",
    "G=nx.Graph()\n",
    "G.add_edges_from(edge_list)\n",
    "\n",
    "#first compute the best partition\n",
    "partition = nx_comm.louvain_communities(G)\n",
    "\n",
    "membership_arr_package = np.zeros((len(data)))\n",
    "for i in range(len(partition)):\n",
    "    for n in partition[i]:\n",
    "        membership_arr_package[n] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1035c57",
   "metadata": {},
   "source": [
    "# Plot UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "membership_arr_louvain = np.load('membership_arr_louvain_large_k5_t10000_knn.npy')\n",
    "membership_arr_gmm = np.load('membership_arr_gmm_23.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "puF.plot_umap(large_data, [membership_arr_louvain, membership_arr_gmm, ], ['Louvain', 'GMM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb2abb",
   "metadata": {},
   "source": [
    "# Get Marker Genes and plot violin plots\n",
    "\n",
    "Will save a dictonary of marker genes for each cluster and plot violin plots for top 3 genes for each cluster. Requires original data before dimension reduction. Have not tested on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb97671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membership_arr_louvain = np.load('membership_arr_louvain_large_k5_t10000_knn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e914726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_file = os.path.join(r'./data', 'data_mtg_loaded.hdf5')\n",
    "membership_arr_louvain = mgF.collapse_small_clusters(membership_arr_louvain, num_max=23)\n",
    "clusters = np.unique(membership_arr_louvain)\n",
    "median_arr, mean_arr = mgF.get_gene_stats_by_cluster(data_file, membership_arr_louvain.reshape(-1), clusters)\n",
    "mgF.filter_genes_by_median(median_arr, mean_arr)\n",
    "save_dir = './output'\n",
    "mgF.plot_marker_genes(data_file, clusters, membership_arr_louvain.reshape(-1), save_dir = save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa71b6a",
   "metadata": {},
   "source": [
    "# Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3123fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_centres = ev.calculate_cluster_centroids(membership_arr_louvain, large_data)\n",
    "louvain_di = ev.dunn_index(membership_arr_louvain, large_data, louvain_centres)\n",
    "louvain_sc = ev.silhouette_coefficient(membership_arr_louvain, large_data, louvain_centres)\n",
    "\n",
    "gmm_centres = ev.calculate_cluster_centroids(membership_arr_gmm, large_data)\n",
    "gmm_di = ev.dunn_index(membership_arr_gmm, large_data, gmm_centres)\n",
    "gmm_sc = ev.silhouette_coefficient(membership_arr_gmm, large_data, gmm_centres)\n",
    "\n",
    "di = np.asarray([louvain_di, gmm_di])\n",
    "sc = [louvain_sc, gmm_sc]\n",
    "\n",
    "ev.plot_evaluation_metric(di, ['Louvain','GMM'], \"Dunn Index\", output_folder = './output')\n",
    "ev.plot_evaluation_metric(\n",
    "        sc, ['Louvain', 'GMM'], \"Silhouette Coefficient\", output_folder = './output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e8369",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run GNB on Louvain labels\n",
    "X = data\n",
    "y = np.array([int(n) for n in membership_arr_louvain])\n",
    "features = [x for x in range(X.shape[1])]\n",
    "classes = np.unique(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = gnb.train_test_split(X, y, test_size = 0.3, random_state = 0, stratify=y)\n",
    "\n",
    "priors_data = gnb.calculate_class_priors(y_train)\n",
    "param = gnb.calculate_param(X_train, y_train)\n",
    "pred_pca = np.array(gnb.predict(X_test, features, classes, priors_data, param))\n",
    "print(\"GNB accuracy on 500 points:\", gnb.accuracy_score(pred_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = mgF.collapse_small_clusters(membership_arr_gmm, num_max=17)\n",
    "new_labels = new_labels[new_labels != np.max(new_labels)]\n",
    "\n",
    "cl, counts = np.unique(new_labels, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(cl, counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Class distribution for gmm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a624a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on large data.\n",
    "import dataFunctions as dF\n",
    "import importlib\n",
    "importlib.reload(ev)\n",
    "importlib.reload(mgF)\n",
    "importlib.reload(dF)\n",
    "\n",
    "X_large = large_data\n",
    "\n",
    "new_labels = mgF.collapse_small_clusters(membership_arr_gmm, num_max=17)\n",
    "print(np.unique(new_labels))\n",
    "X_large = large_data[new_labels != np.max(new_labels)]\n",
    "# X_large = large_data\n",
    "\n",
    "new_labels = new_labels[new_labels != np.max(new_labels)]\n",
    "\n",
    "y = np.array([int(n) for n in new_labels])\n",
    "features = [x for x in range(X_large.shape[1])]\n",
    "classes = np.unique(y)\n",
    "print(classes)\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = gnb.train_test_split(X_large, y, test_size = 0.5, random_state=42, stratify=y)\n",
    "X_train, y_train, X_test, y_test = dF.split_data(X_large, y)\n",
    "\n",
    "\n",
    "priors_data = gnb.calculate_class_priors(y_train)\n",
    "param = gnb.calculate_param(X_train, y_train)\n",
    "pred_pca = np.array(gnb.predict(X_test, features, classes, priors_data, param))\n",
    "print(\"GNB accuracy on 16155 points:\", gnb.accuracy_score(pred_pca, y_test))\n",
    "\n",
    "ev.confusion_matrix(y_test, pred_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
